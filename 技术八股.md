# 常见设计模式
## 单例模式
一般应用在redis连接；kafka consumer；向量库client
## 工厂模式
### 核心思想
解耦对象的创建和使用
### 具体的实现逻辑
```python
class RetrieverFactory(ABC):
    @abstractmethod
    def create_retriever(self) -> BaseRetriever: ...

class FAISSRetrieverFactory(RetrieverFactory):
    def create_retriever(self):
        # 这里可以包含复杂的本地加载逻辑、索引路径检查等
        index = load_faiss_index("./data")
        return FAISSRetriever(index)

class ElasticSearchRetrieverFactory(RetrieverFactory):
    def create_retriever(self):
        # 这里包含复杂的网络连接、鉴权逻辑等
        client = connect_es(host="localhost", port=9200)
        return ESRetriever(client)
```
### rag中应用
根据配置切换ebd模型；根据不同数据源，选择retriever。
### 工厂方法模式和简单工厂
简单工厂：抽象产品、具体产品、核心工厂（if-else实现）
工厂方法：抽象产品、具体产品、抽象工厂（返回抽象产品）、具体工厂（覆盖抽象工厂方法，返回具体产品）

| **特性**     | **简单工厂**     | **工厂方法**           |
| ---------- | ------------ | ------------------ |
| **判断逻辑位置** | 集中在唯一的一个工厂类中 | 分散在各个具体的子类工厂中      |
| **增加新产品**  | 需要修改工厂类的逻辑判断 | 仅需新增产品类和对应的子工厂类    |
| **符合开闭原则** | 否            | 是                  |
| **复杂度**    | 低（代码量少，易于理解） | 中（类结构层次较深）         |
| **适用场景**   | 产品种类较少且固定的情况 | 产品种类经常变动或需要高度解耦的情况 |
## 策略模式
### 核心思想
定义一系列算法，把它们一个个封装起来，并且使它们可以相互替换。简单来说，它的作用就是消除代码中臃肿的 `if-else` 或 `switch-case` 语句，让系统在运行时能动态地选择执行逻辑。把“算法的变化”独立封装，对外暴露统一接口
### 具体的实现逻辑
 ```python
class Retriever:
	def retrieve(self, query): ...

class VectorRetriever(Retriever): ...
class BM25Retriever(Retriever): ...
class HybridRetriever(Retriever): ...
 ```

### rag中应用
不同chunk切分、不同召回、重排策略的可插拔实现

## 观察者模式
### 核心思想
定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新
### 实现逻辑
#### 定义抽象层
```python
from abc import ABC, abstractmethod

# 观察者接口
class Observer(ABC):
    @abstractmethod
    def update(self, data): pass

# 主体接口
class Subject(ABC):
    def __init__(self):
        self._observers = []

    def attach(self, observer: Observer):
        self._observers.append(observer)

    def notify(self, data):
        for observer in self._observers:
            observer.update(data)
```
#### 具体实现
```python
class DocumentManager(Subject):
    """主体：负责文档的增删改"""
    def add_document(self, doc_name):
        print(f"--- 系统：上传了新文档 {doc_name} ---")
        self.notify(doc_name)

class Indexer(Observer):
    """观察者1：负责更新向量索引"""
    def update(self, data):
        print(f"[索引模块] 正在为 {data} 生成 Embedding 并存入向量库...")

class Logger(Observer):
    """观察者2：负责记录日志"""
    def update(self, data):
        print(f"[日志模块] 记录操作：用户于 14:00 上传了 {data}")
```
### rag应用
命中率统计
token消耗统计
延迟监控
失败率监控
### 特点
- 易于扩展，写一个观察者并且注册即可
- 异步友好
## 装饰器模式
### 核心思想
动态地给一个对象添加额外的职责，不影响其原始功能。
实际上就是@表示的装饰器。
一般不允许改变原函数的本质意图
### 实现逻辑
装饰器类和被装饰类必须实现同一个接口
#### 定义统一接口
```python
from abc import ABC, abstractmethod

class ChatBot(ABC):
    @abstractmethod
    def response(self, prompt: str) -> str:
        pass
```
#### 实现基础的核心功能
```python
class BasicChatBot(ChatBot):
    def response(self, prompt: str) -> str:
        return f"这是对 '{prompt}' 的基础回答"
```
#### 定义装饰器基类
装饰器内部必须持有一个 `ChatBot` 对象的引用
```python
class BotDecorator(ChatBot):
    def __init__(self, bot: ChatBot):
        self._bot = bot

    def response(self, prompt: str) -> str:
        return self._bot.response(prompt)
```
#### 实现功能叠加
```python
class LoggingDecorator(BotDecorator):
    """增加日志记录功能的装饰器"""
    def response(self, prompt: str) -> str:
        print(f"[日志] 收到提问: {prompt}")
        result = self._bot.response(prompt)
        print(f"[日志] 回答完成")
        return result

class TranslationDecorator(BotDecorator):
    """增加翻译功能的装饰器"""
    def response(self, prompt: str) -> str:
        # 模拟将 prompt 翻译成英文再调用
        translated_prompt = f"English_Version_of_{prompt}"
        return f"【翻译版】: {self._bot.response(translated_prompt)}"
```
### rag应用
- 权限控制
- 缓存（如果同样的请求来过，直接返回）
- 日志
- debug trace
- 限流
- 返回结果的敏感词过滤
- 性能监控（耗时等）
## 锁的实现方式
分布式锁
# redis
放在内存中的高并发低延迟的内存型key-value存储数据库
主要作用：挡在慢东西前面，如mysql等数据库

## 常见用途
- 缓存数据库查询结果（最常见）
- 保存临时状态：验证码、请求上下文、登陆态等，利用自动过期特性
- 作为微服务、rag等的状态仓库
- 计数、限流
- 简单的队列：异步任务、日志缓冲等
## 速度快的核心原因
- 数据保存在内存
- 单线程模型，可以避免锁
- 使用简单数据结构
## 注意的要点
- 加入所有的key，一定要设置自动过期时间
- redis并非数据库
- redis是可丢层，挂了整个系统应该还能跑

## RAG中的用途
### ebd缓存
embedding慢、贵，而且query可能高度重复
因此，为query缓存其embedding结果
### 检索缓存
向量库查询及IO成本较高，同时，企业的FAQ重复率极高
可以对检索出来的文档进行缓存
### pipeline状态中枢
rag是多阶段流水线，因此，需要将request的状态存下来，供不同的阶段进行使用
```
req:{request_id} → {
  query,
  embedding_status,
  retrieval_status,
  rerank_status,
  llm_status
}
```
### 权限控制
使用redis进行权限控制，为不同角色展示不同的文档结果
### 语义缓存
当一个新 Query 进来时，先转成向量，去 Redis 里找有没有“长得像”（向量搜索，判断距离）的旧 Query，如果有，返回旧query对应的回答。
、context缓存
## rag中key的设计
### 设计规范
- 工程化，如user:1001；emb:hash
- 结构统一：前缀 + 业务语义 + 标识，如{system}:{module}:{identifier}，rag:req:uuid这种
- 写过期时间
- 存副本、中间态，要求可丢、可重建、可降级
### 设计的key参考表
| 类别           | Key 模板                   | Value       | TTL     |
| ------------ | ------------------------ | ----------- | ------- |
| Embedding 缓存 | `rag:emb:{q_hash}`       | vector      | 1–7 天   |
| 检索结果缓存       | `rag:ret:{emb_hash}`     | doc_id list | 5–30 分  |
| 请求状态         | `rag:req:{uuid}`         | hash        | 10–30 分 |
| 权限映射         | `rag:acl:{doc_id}`       | role set    | 长       |
| 用户角色         | `rag:user:{uid}:role`    | role set    | 长       |
| Prompt 版本    | `rag:prompt:{ver}`       | template    | 长       |
| 答案缓存         | `rag:ans:{q_hash}:{ver}` | answer      | 10–60 分 |
| 限流           | `rag:rate:{ip}`          | counter     | 1 分     |
# kafka
Kafka 是一个高吞吐、可持久化、可横向扩展的“分布式消息日志系统”。
## 核心角色
- producer：只写消息
- broker：kafka节点，是服务器进程，但机器可跑多个，负责存数据
- topic：消息的逻辑分类，类似文件夹
- partition：topic拆为多个分区，是一个**只能追加写**的有序日志文件
- consumer：从kafka拉消息，自己决定读到哪里
- 消费者组：主要用于负载均衡，topic的分区会被均匀分给组内的消费者。**一个 partition 在一个 consumer group 中，只会被一个 consumer 消费**
## 核心数据模型
```
Topic A
 ├── Partition 0: msg0 msg1 msg2 msg3 ...
 ├── Partition 1: msg0 msg1 msg2 ...
 └── Partition 2: msg0 msg1 ...
```
每条消息有一个offset，在partition中唯一递增，仅由消费者记录
## 消息流
```
Producer
   ↓
选择 Topic + Partition
   ↓
Broker 写入 partition log（顺序写）
   ↓
Consumer pull 消息
   ↓
Consumer 提交 offset

```
## 速度快的原理
- 顺序写磁盘
- page cache、零拷贝（少一次用户态拷贝） #question
- 批量处理：批量发、存、拉
## RAG中的应用
kafka适合处理异步的流程（离线链路）。
数据接入 / 更新 / 分析 / 评估 / 监控
一般应用在：异步ebd生成；失败重试；日志采集；文档入库
### 文档接入&增量更新
这是最常见的使用方式
```yaml
数据源
  ↓
Kafka topic: doc_raw
  ↓
清洗 / 解析 / chunk
  ↓
Kafka topic: doc_chunked
  ↓
Embedding
  ↓
向量库
```
主要作用为解耦数据源和embedding；支持重跑embedding、更换embedding模型、回溯doc历史数据等
### embedding异步化
embedding慢、贵，需要异步执行
典型流程为```doc_chunk → Kafka → embedding worker → vector DB```
+ embedding worker可水平扩展
+ 失败重试/DLQ #question 
+ embedding模型升级可重放kafka offset #question 
### query/answer日志（用于评估/追溯）
主要用于离线评估

### 向量入库
1. 削峰填谷，保护向量库 
2. 向量写入易失败，需要可恢复
3. 支持 embedding / 索引重建（replay）
4. 支持多索引并行消费
5. 天然支持批量写入
### 全流程参考
```mermaid
flowchart LR
    A[文档源] -->|produce| K1[(Kafka: doc_raw)]
    K1 -->|consume| B[清洗 & Chunk]
    B -->|produce| K2[(Kafka: doc_chunked)]
    K2 -->|consume| C[Embedding Worker]
    C -->|produce| K3[(Kafka: embedding_result)]
    K3 -->|consume| D[Indexer]
    D --> E[(Vector DB)]

    Q[User Query] --> F[Query Embedding]
    F --> E
    E --> G[Rerank]
    G --> H[LLM]
    H --> R[Answer]

    H -. async log .-> K4[(Kafka: rag_query_log)]

```
