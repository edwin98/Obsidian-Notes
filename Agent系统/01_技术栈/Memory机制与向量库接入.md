---
tags:
  - Agent
  - 记忆系统
  - RAG
status: draft
---
# Memory机制与向量库接入 (短期记忆与长期记忆)

AI Agent 系统如果缺乏记忆系统，不仅会患上“金鱼记忆”，更是无法在长周期的复杂任务流中持续工作。针对 LLM 无法长期保存会话上下文的缺陷，建立合理、高效的 Memory （记忆）管理架构是当今极其热门的设计思路。

一个完整的 Agent 记忆系统，通常会被学术界及业界分为**短期记忆（Short-term Memory）**与**长期记忆（Long-term Memory）**。

## 1. 短期记忆 (对话上下文管理)

大模型的每次调用都是无状态（Stateless）的。如果不把之前的对话通过请求发给它，它永远不知道上一句聊了什么。短期记忆就是我们常见的 Context / Message History。但它的瓶颈在于 **Token 窗口限制**。

### 常见的短期记忆管理策略：
1. **记忆缓冲区 (Buffer Memory)**:
   - 全盘保留。将所有的 `HumanMessage`, `AIMessage`, `ToolMessage` 按顺序拼接放入 Prompt。
   - *缺点*: 上下文急剧膨胀，容易触发上限且花销昂贵。若没有无限长窗口如 Gemini 1.5 Pro，难以长久维持。
2. **滑动窗口截断 (Window Memory)**:
   - 只给 LLM 喂最近的 K 轮对话记录（比如过去 5 轮）。将太早的历史暴力丢退。
   - *缺点*: 对于之前讨论的关键主旨、人名、设定的条件极易彻底遗忘。
3. **对话摘要 (Summary Memory)**:
   - 另设一个较小的轻量级 LLM 或者在固定轮数时对之前的多轮对话进行文本总结（Summarize）。
   - 让主模型只阅读：`【历史摘要】 + 【最近一轮提问】`。这极大地压缩了信息密度，同时兼顾了长链路。当前各大生产环境非常推崇此方法。
4. **状态保留 (State graph)**:
   - 在如 LangGraph 等框架中，将系统当前到达的一个检查点或者收集到的核心变量（例如客户姓名、需求状态：已报价、未付款等）放在共享 State 字典中。这不属于会话历史，属于有目的提取的业务主键。

## 2. 长期记忆 (持久化与知识库管理)

当 Agent 被暂停、关闭、甚至跨越数个月再次激活聊天时，短期记忆显然力不能及。此时我们使用外部知识存储（通常结合 RAG 技术），为 Agent 提供无限量的内容管理库。

长期记忆的核心逻辑为：**信息写入 ➔ 构建索引/向量 ➔ 相似性或元数据检索 ➔ 提词增强 (RAG)**。

### RAG 在 Agent 中的两种典型用法

1. **作为被动工具（Tools for Querying retrieval）**:
   - 把查询 Chroma、Milvus 向量库的函数包装成一个 `Tool`。
   - 比如提供 `search_internal_knowledge_base` 工具，当 Agent 针对你的开源项目或者内部代码提出问题时，模型主动决定调用工具。这种做法使得大模型有主导权，能够多次循环去抽取不同字段，组合分析出复杂长文信息。
2. **作为前置路由或者环境注入（Context Injection）**:
   - 即传统的 RAG 方式：无论大模型是否需要，我们在用户提问发给 LLM 之前，先把问题转成向量进行最近邻查询，然后拼接进 System Prompt：“`你是一个客服。根据以下提供的背景资料 [背景 A] [背景 B] 回答问题。`”这种方式对延迟最友好，不易引起模型的误叛工具现象。

### 主流开源向量库（Vector Stores）选型
1. **轻量级/本地化首选 (适合快速原型/小型项目)**:
   - **Chroma** (`chromadb`): 使用 SQLite，开箱即用，极其适合和 LangChain 串联做快速的概念验证（PoC）。
   - **FAISS**: Meta 开源的高效相似性搜索库，纯算法不提供独立服务端，需在代码中管理。
2. **企业级开源 / 大型分布式**:
   - **Milvus / Zilliz**: 能够处理十亿级别甚至千亿级别的向量匹配，在架构支持、分片扩展上有极其成熟的表现。
   - **Qdrant**: 使用 Rust 编写，支持复杂过滤规则的高级查询引擎，近年来口碑极高。
3. **混合利用现存的数据库（Postgres, Redis）**:
   - 当前绝大多数公司并不愿意马上引入新的技术栈。
   - **pgvector**: Postgres 专门的向量查询插件，极大方便了同时存取业务 SQL 数据和向量数据的需求。
   - **Redis Search**: 若系统本身重度依赖 Redis 缓存，使用其红黑树与向量组合也是应对高频低延迟对话存储的最佳手段。

---

## 3. 面向未来的记忆模式（MemGPT 等）

学术界的前沿不仅仅停留在“截断”与“RAG”的缝合阶段，类似 **MemGPT（OS 操作系统的分页缓存理念）**等项目正在探索**大模型如何通过工具自己管理存储块（主动地读取/写入数据库）**。
- 让大模型根据指令，自己决定把“用户很不喜欢吃辣”这条信息主动调用工具去写入长期磁盘。
- 需要的时候，自己写 SQL 或查询把该偏好读取（Fetch）进入主内存缓存（Main Context）。

构建一个好的 Memory 模块是 Agent 要走向个性化（Personalization）服务的必经之路。因为没有记忆，Agent 也就是无感情且记不住教训的流水线问答器而已。
