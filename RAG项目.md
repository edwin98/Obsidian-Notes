# 背景
无线豆包是ICT AI辅助工作的重点工作，对标秘塔搜索——一个入口、报告式回答、答案可信
## 最终性能
TOP20返回时，E2E准确率93%
# 整体架构
整体可分为知识召回、知识库构建、知识预处理
**知识召回**：
- 多路召回：改写为三个问题，基于三个问题检索
- 三级找回：初筛、二筛、精排
- 混合召回：BM25关键字检索+向量检索
**知识库构建**：
- 向量知识库
- BM25词频库：通过无线专有词表，保证独立语义的词语不被分开
**知识预处理**：
- 知识标签：1+X+Y架构设计，保证知识有序存储。**关键**
- 知识切片：不同知识使用不同的切片方式
- 知识清洗：不同知识来源及格式，使用不同的清洗方式
## 多路召回
### 目的
将用户query相关的全部知识都找出来
### 主要内容
1. 将指代内容进行翻译，如多轮问答中，“随机接入是什么”，“它有什么关键技术”->"随机接入有什么关键技术"
2. 将原始啥问题扩充为1~3个问题，以适应RAG检索。如“CA是什么”->“载波聚合是什么”
#### 实现流程：
prompt+LLM。在用户的输入基础上，进行属于识别提取，提供给LLM作为context。使用Qwen3-4B进行query改写，模型的选择权衡准确度和时间，当前能达到1s内
#### prompt的设计方式
##### user prompt
- 目标
- 受众
- 规则
	- 多轮问题解析规则
		- 指代词推断
		- 主语切换但意图延续的场景合理改写
		- 时间描述的推断
		- 人称指代的替换（如用户信息）
		- 相关的示例
	- 术语和关键词提取
	- 问题改写
	- 相关性排序
	- 最终输出
##### system prompt
- 目标
- 输出格式（对于json的限制描述）
- 输出示例
## 三级召回
仅使用了一个ES库，因此为了保证稳定检索，使用3曾找回
1. 第一层BM25+384维向量库检索，各1500条，共3000条（实验发现准确率99%以上）。输入无线统一知识库，输出3000篇文档
2. 第二层BM25+768维向量库检索，按照用户SAP调整权重配比。输入3000篇文档+员工画像；输出80文档
3. 第三层rerank精排，模型选择[gte-multilingual-reranker-0.3B](https://huggingface.co/Alibaba-NLP/gte-multilingual-reranker-base)，输入80文档，输出10文档
三级召回耗时2s。第一层0.5s，第二层0.5s，第三层1s
>[!question] 为什么要用两个维度的向量库
## 混合召回
混合召回是在三级召回中的第二层中的策略。具体是指：向量匹配侧重于语义，BM25基于关键字匹配
### 具体实现
RSF算法实现（Rank Score Fusion）
1. 向量召回160文档，BM25召回160文档
2. 向量召回、BM25召回的得分归一化
3. 将二者加权求和，得到总得分
4. 对总得分排序，返回前80文档
权重$\alpha$的设置：根据用户tokens动态设置，问题短则偏BM25，问题长则偏向量，公式如下：
$$\alpha = 0.4 + \frac{0.3}{1 + e^{-\frac{L - k}{s}}}$$
- **$L$**：用户查询的 Token 数量。
- **$k$**：中心值，设置为8，当长度等于 $k$ 时，$\alpha = 0.55$（正好是 $0.4$ 与 $0.7$ 的中点）。
- **$s$**：平滑系数，设置为1，控制从 $0.4$ 切换到 $0.7$ 的坡度。

## 知识库构建
embedding模型的选择：[gte-multilingual-base](https://huggingface.co/Alibaba-NLP/gte-multilingual-base)，基于此模型进行微调。微调的过程重点在于高质量语料的构建。
构建方式：基于qwen2.5 72B，自动生成语料对。
基于不同的数据内容，利用prompt指示大模型，生成json格式的QA对，生成75wQA对，数据处理后48w参与微调，在A30 * 2 上训练两周
要点：
- 保证问题的丰富性：分别从文档块、文档块标题、文档块生成摘要，摘要作为问题，直接从文档块生成问题、答案
- 后处理的必要性：需要进行异常字符剔除、minhash问题去重、rerank筛选、去除指代性问题（包含本文、这、那这种字符）
- 长度配比要搭配，使用不同长度的语料进行训练
- 同时微调多个维度

全流程的过程
补充框架图  [[ToDo]]
设计原则
哪些同步、哪些异步
性能瓶颈点
# 基层模型的选择
选择的因素
# chunk方式
chunk的单位
不同文档的chunk策略

# prompt设计
# 权限设计
检索过滤方式
embedding和权限控制的顺序
# 性能和成本
查询耗时及分布（embedding、rerank、llm）
# 评估方式
指标
离线评估、在线评估？
如何区分不同失败场景？检索、rerank、幻觉
# 数据预处理
数据清洗
结构化抽取
表格、图片处理方式
## 词表构建方式
AutoPxx
# 上下文处理方式
记忆处理方式
# 索引方式
向量库的选择
索引更新
# 重排方式
重排收益、延迟
# 失败处理方式
定义
兜底策略
防止hallucination prompt设计
# 使用人次及评价
迭代
迭代频率
# 框架选择
选择原因
自己封装的组件
遇到过的坑
# 压力测试
# 代码实现细节
## 前端的框架
## 后段框架及技术栈
## 前后端是怎么交互的
## 非阻塞时响应怎么做的
## 对话记忆的底层实现

# 多模态的处理