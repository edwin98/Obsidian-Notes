# 背景

无线豆包是 ICT AI 辅助工作的重点项目，对标秘塔搜索，核心理念为：**一个入口、报告式回答、答案可信**。

## 最终性能

在 TOP20 召回条件下，端到端（E2E）准确率达到 **93%**。

---

# 整体架构

系统整体分为**知识召回**、**知识库构建**、**知识预处理**三大模块：

**知识召回：**
- **多路召回**：将原始问题改写为多个子问题，基于多问题并行检索，提升召回覆盖率
- **三级召回**：初筛 → 二筛 → 精排，逐层缩小候选集并提升精度
- **混合召回**：融合 BM25 关键字检索与向量语义检索，兼顾精确匹配与语义理解

**知识库构建：**
- **向量知识库**：基于微调后的 Embedding 模型构建
- **BM25 词频库**：基于无线领域专有词表，保证独立语义的词语在分词时不被拆分

**知识预处理：**
- **知识标签**：采用 1+X+Y 架构设计，保证知识有序存储与分类管理（**关键设计**）
- **知识切片**：针对不同知识类型采用差异化切片策略
- **知识清洗**：根据知识来源和格式，定制相应的清洗方式

---

## 多路召回

### 目的

将与用户 Query 相关的全部知识尽可能**召回完整**，避免因单一检索路径遗漏关键信息。

### 主要内容

多路召回包含两个核心步骤：

1. **指代消解**：还原多轮对话中的指代内容。例如：多轮问答中，"随机接入是什么" → "它有什么关键技术" ⇒ 改写为 "随机接入有什么关键技术"。
2. **问题扩展**：将原始问题扩展为 1~3 个语义等价或相关的检索问题，以提高 RAG 检索的命中率。例如："CA 是什么" → 扩展为 "载波聚合是什么"。

#### 实现流程

采用 **Prompt + LLM** 的方案：在用户输入的基础上进行属性识别与提取，将识别结果作为上下文提供给 LLM。使用 **Qwen3-4B** 执行 Query 改写，该模型在准确度与推理时延之间取得了较好的平衡，当前单次改写耗时可控制在 **1s** 以内。

#### Prompt 设计

##### User Prompt
- **目标**：明确改写的任务目标
- **受众**：定义目标用户角色
- **规则**：
	- 多轮问题解析规则
		- 指代词推断
		- 主语切换但意图延续的场景合理改写
		- 时间描述的推断
		- 人称指代的替换（如结合用户信息）
		- 相关示例
	- 术语和关键词提取
	- 问题改写策略
	- 相关性排序逻辑
	- 最终输出格式

##### System Prompt
- **目标**：定义模型角色与任务边界
- **输出格式**：JSON 结构约束描述
- **输出示例**：标准化的输出样例

---

## 三级召回

系统仅使用一个 Elasticsearch 库，为保证检索的稳定性与准确性，采用**三层渐进式召回**策略：

1. **第一层（粗筛）**：BM25 + 384 维向量库检索，各召回 1500 条，合并后共 3000 条（实验验证该层准确率达 **99% 以上**）。输入为无线统一知识库，输出 3000 篇候选文档。
2. **第二层（精筛）**：BM25 + 768 维向量库检索，基于用户 SAP 画像动态调整两种召回方式的权重配比。输入 3000 篇文档 + 员工画像信息，输出 80 篇文档。
3. **第三层（精排）**：使用 Rerank 模型进行精排，模型选择 [gte-multilingual-reranker-0.3B](https://huggingface.co/Alibaba-NLP/gte-multilingual-reranker-base)。输入 80 篇文档，输出最终 **10 篇**高相关文档。

**耗时分布**：三级召回整体耗时约 **2s**（第一层 0.5s，第二层 0.5s，第三层 1s）。

> [!question] 为什么要用两个维度的向量库？
> 384 维向量在第一层大规模粗筛中计算效率更高，适合从海量文档中快速缩小候选集；768 维向量语义表达能力更强，在第二层较小候选集上可提供更精准的语义排序。两者配合实现了效率与精度的平衡。

---

## 混合召回

混合召回是三级召回中**第二层**的核心策略：向量匹配侧重**语义相似度**，BM25 侧重**关键字精确匹配**，两者互补。

### 具体实现

采用 **RSF（Rank Score Fusion）** 算法：

1. 向量召回 160 篇文档，BM25 召回 160 篇文档
2. 分别对两路召回的得分进行**归一化**处理
3. 将归一化后的得分**加权求和**，计算综合得分
4. 按综合得分排序，返回 **Top 80** 文档

**动态权重 $\alpha$ 的设置**：根据用户 Query 的 Token 数量动态调整权重——短问题偏向 BM25（关键字匹配优势），长问题偏向向量（语义理解优势）。权重计算公式如下：

$$\alpha = 0.4 + \frac{0.3}{1 + e^{-\frac{L - k}{s}}}$$

- **$L$**：用户查询的 Token 数量
- **$k$**：中心值，设为 8。当 $L = k$ 时，$\alpha = 0.55$（即 $0.4$ 与 $0.7$ 的中点）
- **$s$**：平滑系数，设为 1，控制权重从 $0.4$ 到 $0.7$ 过渡的坡度

---

## 知识库构建

### 向量知识库

**Embedding 模型选择**：基于 [gte-multilingual-base](https://huggingface.co/Alibaba-NLP/gte-multilingual-base) 进行领域微调。微调的核心在于**高质量训练语料的构建**。

**语料构建方式**：使用 **Qwen2.5-72B** 自动生成训练语料对。针对不同类型的数据内容，通过 Prompt 引导大模型生成 JSON 格式的 QA 对。共生成 **75 万** QA 对，经数据处理后 **48 万**条参与微调训练，在 **A30 × 2** 上训练两周。

**核心要点**：
- **问题丰富性**：分别从文档块内容、文档块标题、文档块生成的摘要等多角度出发；摘要可直接作为问题，也可基于文档块同时生成问题与答案
- **后处理的必要性**：异常字符剔除、MinHash 问题去重、Rerank 相关性筛选、去除指代性问题（含 "本文""这""那" 等模糊指代词）
- **长度配比平衡**：使用不同长度的语料进行训练，避免模型对特定长度的偏好
- **多维度联合微调**：同时微调 384 维和 768 维向量表示

**微调效果**：
- 自有数据集：Top10 召回率从 **62% → 88%**（提升 26 个百分点）
- 开源数据集 [DuRetrieval](https://huggingface.co/datasets/mteb/DuRetrieval)：98.8% → 97.8%（微降 1 个百分点，属于合理范围，表明模型在领域适配的同时未严重损失通用能力）

### BM25 词频库

BM25 词频库的构建有两个核心要点：

1. **单一知识库设计**：由于知识总量庞大，为降低维护复杂度和保障检索一致性，仅建立一个统一的 BM25 知识库
2. **分词准确性**：TF-IDF 的正确计算依赖于准确的文本分词，因此需要构建无线领域专有词表，确保领域术语不被错误切分

#### 词表构建流程

1. **语料汇集**：将 DTS 工单内容、Support 网站全部支持文档、全部 IDP 文档作为语料库
2. **语料清洗**：去重、去除目录页、去除特殊符号、剥离 HTML 标签等
3. **种子词表构建**：爬取华为术语库内容作为基础正标签（约 5000 词）；抽取维基百科高频词作为通用领域负样本
4. **新词发现**：使用 **AutoPhrase** 算法自动发现新词，强制保留 "名+名" 或 "形+名" 结构，大幅过滤无意义的动词性短语
5. **人工迭代校正**：将人工确认的正确词作为标签数据，重复执行 AutoPhrase 迭代。最终发现约 10000 词。人工校正时**优先挑选算法评分在 0.5 左右的边界样本**，以最大化每轮迭代的标注增益
6. **LLM 辅助过滤**：使用 **Qwen2.5-72B** 对候选词进行打分过滤，结合人工审核，最终得到 **6800** 个有效领域词

---

## 知识预处理

> **核心原则**：所有文本内容统一转换为 Markdown 格式；基于 Markdown 结构的切片策略以最大程度保留语义完整性。

### 知识格式处理

**不同文件格式的处理方式**：

| 格式 | 处理方式 |
|------|----------|
| Word | 转为 Markdown |
| HTML | 转为 Markdown |
| PPTX | 按页处理：转为图片 → OCR 提取文字 → 生成图片链接 |
| Excel / CSV | 转为纯文本 |
| PDF | 转为 Markdown |
| 图片 | 保留链接；链接不参与检索召回，仅参与最终总结生成 |

**不同数据源的针对性处理**：

| 数据源 | 处理策略 |
|--------|----------|
| Support 文档 | 增加目录结构信息；特定内容增加标签（如 gNodeB 增加 5G 标签） |
| Wiki | 增加目录层级信息 |
| iCase（反思案例） | 内容不做切片处理，标题增加产品信息 |
| 设计文档 | 仅保留最新版本，增加 PDU 信息 |
| 3GPP 协议 | 缩进格式适配；文件名与协议编号重映射 |
| 华为知道、华为案例 | 不切片，整篇入库 |

### 知识切片

采用**基于章节结构的层次化切分**策略，按节点类型分为三类：

- **非叶子节点**：包含子章节的文本段。若总长度 > 2K Token，则由 LLM 生成摘要作为替代 Chunk，同时继续向下递归切割；若 ≤ 2K Token，直接作为 Chunk
- **叶子节点**：文档末端的纯内容段落，按固定步长结合语义换行进行切割
- **无标题节点**：连续长文本、代码块或公式组，强制继承最近的有效标题

| 维度 | 非叶子节点（章节层级） | 叶子节点（最小语义单元） | 无标题 / 特殊节点（正文块） |
|------|------------------------|--------------------------|----------------------------|
| 判定标准 | 带有子标题的导航层级（如 `#` / `##`） | 文档末端的纯文本 / 细节描述段落 | 连续长文本、代码块、或数学公式组 |
| 切分规模 | 阈值：2K Tokens | 512 ~ 800 Tokens | 继承父级大小，按语义边界对齐 |
| 核心动作 | ≤2K：保留全文并打标；>2K：LLM 生成摘要作为替换块 | 固定步长 + 语义换行切割 | 强制关联：继承最近一个有效标题 |
| 重叠度（Overlap） | N/A（由摘要覆盖全局语义） | 10% ~ 15% | 保持上下文连贯，避免截断公式 / 代码 |
| 元数据注入 | 包含子节点 ID 列表、层级路径 | 回填父级摘要、层级路径、原始页码 | 标注 `is_continuation: true` |
| 检索价值 | 解决 "宏观 / 综述类" 问题召回 | 解决 "具体事实 / 数值" 问题召回 | 提供技术实现细节、代码片段 |

---

## 知识更新

### 1+X+Y 知识集架构

从两个管理视角出发，形成 **1+X+Y** 的知识分类架构：

- **X（能力视角）**：从 CQIC 能力维度划分，共 7 个方向——设计、软件、硬件、测试、研究、产品管理、项目管理。涵盖产品技术规范、CQIC 建设课程、Wiki、社区文档、博客、案例、需求文档等
- **Y（组织视角）**：从 PDU 维度进行管理，共 8 个方向——基站产品、基站平台、解决方案、MAE、DIS、微波、GUC 等。涵盖 PDU 建设课程、交付大典、Wiki、文档、博客等
- **1（公共视角）**：通用性、跨领域的公共文档，如 IPD 流程、3GPP 协议、无线百科、技术连载、公共业务课程等

> **注意**：同一份文档允许在多个知识集中出现（即允许重复索引），但入库时仅保留一条物理记录，同时**合并所有知识集的标签**。

**知识集架构的设计考量**：
- 用户需要能**可见全部**的知识集
- 每个知识集的构建需要**独立看护**，不同团队优先管理和消费自己领域的知识

因此，知识集的构建过程分为三步：

1. **知识生产者**：将各自领域的知识接入 Athena 知识中心，统一看护与版本管理
2. **知识集构建者**：在 Athena 中选择本领域关注的数据源，组装形成知识集，触发向量库入库流程
3. **数据 IT**：将 1+X+Y 的知识集分别匹配对应的流水线进行知识处理（清洗 → 格式转换 → 切片 → 向量化 → 元数据标签注入），最终送入 RAG 知识库

### 元数据管理 & 标签管理

文档的元数据共分为**四类属性**：

| 属性类别 | 来源 | 内容说明 |
|----------|------|----------|
| **基础属性** | 产生于原作业系统，直接使用 | 文档唯一性标识：文档 ID、名称、作者、原链接、产生时间、创建时间、URL、密级等 |
| **管理属性** | 产生于原作业系统，映射适配 | 文档归属信息：产品、版本、部门、领域等。需屏蔽不同原系统的差异，统一管理 |
| **知识管理属性** | 知识管理作业过程中产生 | 分类标记：CQIC 方向、PDU 归属、适用产品线、数据类型（结构化数据、文档、代码、音频、视频） |
| **召回属性** | 入库时产生 | 检索支撑信息：向量表示、切片内容、权重、切片 ID |

**向量化过程**：支持通用流水线处理，如需特殊处理亦支持各产业自定义适配流水线；切片逻辑可定制；Embedding 模型可按需选择。

---

# 评估方式

## 自研召回评测数据集的背景

公司研发资产具有以下特性：

- **使用场景化**：遵循 IPD 研发流程，资产有特定的消费方式
- **信息复杂化**：包括非结构化文档、结构化数据库、代码仓等多种资产形态
- **高度专业化**：包含大量专业术语及内部流程用语，如 AR、IR 等
- **逻辑关系复杂**：包括增量/全量关系、设计-开发-测试分层挂接文档

因此需要构建**专用的评测集**，以贴合公司的实际应用场景。

## 召回评测集构建方案

从三个能力层级递进评测：

1. **单文档上下文获取**：重点评测 RAG 的基础能力，评估端到端检索链路是否合理
2. **多文档、多跳、复杂上下文获取**：评测进阶能力，如多文档比较、复杂推理等
3. **Agent 作业上下文获取**：评估 RAG 是否能支撑 Agent 精准获取上下文

### 单文档上下文获取能力

主要从以下几个维度出发：

- **多模态格式兼容性**：检索图、表、附件、代码块、文本的能力
- **结构感知与连贯性**：检索单句、长文、多个片段、各级标题的能力
- **语义与边界鲁棒性**：使用同义词、行业术语、特殊用词获取上下文的能力

**三种提问方式**：

| 提问方式 | 说明 |
|----------|------|
| 原文 | 针对检索目标，使用原文构造 Query |
| 总结 | 针对检索目标生成总结性需求 |
| 容错 | 编写具有部分表达错误的 Query |

**评测指标**：仅评价召回率，分为正确召回、部分召回、无召回三个等级。

**评估数据量**：2034 条用例。


指标
离线评估、在线评估？
如何区分不同失败场景？检索、rerank、幻觉
# 数据预处理
数据清洗
结构化抽取
表格、图片处理方式
## 词表构建方式
AutoPxx
# 上下文处理方式
记忆处理方式
# 索引方式
向量库的选择
索引更新
# 重排方式
重排收益、延迟
# 失败处理方式
定义
兜底策略
防止hallucination prompt设计
# 使用人次及评价
迭代
迭代频率
# 框架选择
选择原因
自己封装的组件
遇到过的坑
# 压力测试
# 代码实现细节
## 前端的框架
## 后段框架及技术栈
## 前后端是怎么交互的
## 非阻塞时响应怎么做的
## 对话记忆的底层实现

# 多模态的处理